# ğŸ’Š Prescription Scraping API

This project is a Flask API that automates the download of `.xls` files from the Mexican Government's open data portal. It extracts prescription data issued by public institutions, cleans the data, and exposes the most and least prescribed medications through JSON-based endpoints.

---

## ğŸš€ What Does This API Do?

1. **Automatically downloads `.xls` files** from an official dataset (e.g. INNN).
2. **Stores metadata** like the issuing institution in `.meta.txt` files.
3. **Processes downloaded files** using Pandas: cleans headers and aggregates data.
4. **Exposes cleaned and aggregated information** through a RESTful API.

---

## ğŸ”— Available Endpoints

| Method | Route                     | Description                                                |
|--------|---------------------------|------------------------------------------------------------|
| GET    | `/`                       | Basic health check                                          |
| GET    | `/run-scrape`             | Scrapes and downloads `.xls` files from the dataset        |
| GET    | `/medicinas-externas`     | Returns the top/bottom 10 most prescribed medications      |
| GET    | `/list-files`             | Lists all downloaded files in the local directory          |
| GET    | `/download/<filename>`    | Downloads a specific `.xls` or `.meta.txt` file            |

---

## ğŸ—‚ Folder Structure

```
ğŸ“ Webscrapping/
â”‚   â”œâ”€â”€ Recetas_Emitidas_Abril-Diciembre_2023.xls
â”‚   â”œâ”€â”€ Recetas_Emitidas_Abril-Diciembre_2023.xls.meta.txt
â”‚   â”œâ”€â”€ Recetas_Emitidas_2024.xls.meta.txt
â”‚   â”œâ”€â”€ Recetas_Emitidas_2024.xls
â”‚   â””â”€â”€ ...
â”œâ”€â”€ app.py             # Flask app with endpoints
â”œâ”€â”€ webscrape.py       # Scrapes files and metadata using BeautifulSoup
â”œâ”€â”€ insert_meds.py     # Cleans + loads data into MySQL
â”œâ”€â”€ requirements.txt   # All dependencies
â””â”€â”€ .render.yaml       # Deployment config
```

## ğŸš€ Endpoints


---

## ğŸ“¥ Endpoint: `/run-scrape`

- Scrapes data from: [datos.gob.mx](https://historico.datos.gob.mx/busca/dataset/recursos-materiales-recetas)
- Downloads `.xls` files only (not `.csv`)
- Saves them in the `Webscrapping/` folder
- Generates a `.meta.txt` file for each `.xls`, containing the institution name

---

## ğŸ“Š Endpoint: `/medicinas-externas`

- Processes all `.xls` files in the `Webscrapping/` directory
- Cleans poorly formatted or duplicated columns
- Normalizes column headers (e.g., fixes `"CANTIDAD  PRESCRITA"`)
- Groups by medication and returns:
  - **Top 10 most prescribed**
  - **Bottom 10 least prescribed**

Sample JSON response:

```json
[
  {
    "archivo": "Recetas_Emitidas_2024.xls",
    "tipo": "top",
    "institucion": "INSTITUTO NACIONAL DE NEUROLOGÃA Y NEUROCIRUGÃA",
    "medicamento": "PARACETAMOL",
    "cantidad": 13782,
    "fecha_archivo": "2024-01-01"
  },
  ...
]
```

## â˜ï¸ Deployment on Render

1. Push your code to GitHub
2. Create a new **Web Service** on [Render](https://render.com)
3. Link your GitHub repository
4. Set the build command:

```bash
   pip install -r requirements.txt
```

5. Set the start command:

```bash
   gunicorn app:app
```

# Run endpoints
```
#Run flask locally
flask run
```
